{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeduardo22/FIAP/blob/main/reconhecimento_emocoes_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lgSf9suEtNf-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "lgSf9suEtNf-",
        "outputId": "78ddee40-c6f4-4c11-e9ad-1d9a869391cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processando vídeo: 100%|██████████| 3326/3326 [40:41<00:00,  1.36it/s]\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a2823bf9e0de>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Chamar a função para detectar emoções no vídeo e salvar o vídeo processado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mdetect_emotions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-a2823bf9e0de>\u001b[0m in \u001b[0;36mdetect_emotions\u001b[0;34m(video_path, output_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Caminho para o arquivo de vídeo na mesma pasta do script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def detect_emotions(video_path, output_path):\n",
        "    # Capturar vídeo do arquivo especificado\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Verificar se o vídeo foi aberto corretamente\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erro ao abrir o vídeo.\")\n",
        "        return\n",
        "\n",
        "    # Obter propriedades do vídeo\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Definir o codec e criar o objeto VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para MP4\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Loop para processar cada frame do vídeo\n",
        "    for _ in tqdm(range(total_frames), desc=\"Processando vídeo\"):\n",
        "        # Ler um frame do vídeo\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Se não conseguiu ler o frame (final do vídeo), sair do loop\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Analisar o frame para detectar faces e expressões\n",
        "        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "        # Iterar sobre cada face detectada\n",
        "        for face in result:\n",
        "            # Obter a caixa delimitadora da face\n",
        "            x, y, w, h = face['region']['x'], face['region']['y'], face['region']['w'], face['region']['h']\n",
        "\n",
        "            # Obter a emoção dominante\n",
        "            dominant_emotion = face['dominant_emotion']\n",
        "\n",
        "            # Desenhar um retângulo ao redor da face\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "            # Escrever a emoção dominante acima da face\n",
        "            cv2.putText(frame, dominant_emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
        "\n",
        "        # Escrever o frame processado no vídeo de saída\n",
        "        out.write(frame)\n",
        "\n",
        "    # Liberar a captura de vídeo e fechar todas as janelas\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Caminho para o arquivo de vídeo na mesma pasta do script\n",
        "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "script_dir ='/content/drive/MyDrive'\n",
        "print (script_dir)\n",
        "\n",
        "\n",
        "input_video_path = os.path.join(script_dir, 'pose1.mp4')  # Substitua 'meu_video.mp4' pelo nome do seu vídeo\n",
        "output_video_path = os.path.join(script_dir, 'output_video_faces.mp4')  # Nome do vídeo de saída\n",
        "\n",
        "# Chamar a função para detectar emoções no vídeo e salvar o vídeo processado\n",
        "detect_emotions(input_video_path, output_video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3n2-q834t7U0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2-q834t7U0",
        "outputId": "581a17ae-cd2b-4ad6-ce4d-ed1c017a68ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}